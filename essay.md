## 22.11.23, 24.11.23

Прочитал задание и начал разбор с попыток запуска приложения. Попутно оформлял README.md. 

Довольно быстро определился с ключами запуска, потом с помощью strace выяснил, какие файлы и папки ожидает приложение. После запуска нашел порт, который оно слушает.

Собрал Dockerfile и docker-compose для локального запуска. Включил в него `postgresql` и `adminer`. Сделал init-контейнер для заполнения БД. Добавил `nginx`. 

Тестировал этот стек примерно пару дней, наблюдая за работой. Попробовал запустить две копии приложения одновременно. Падали они тоже одновременно...

(Итоговый вариант локального стека [здесь](./build/docker-compose.yml))

После этого стала вырисовываться требующаяся архитектура:

- postgresql
- две docker-ноды (docker-compose) для запуска приложения
- nginx в качестве балансера нагрузки
- nginx (еще один?) в качестве кэширующего прокси

## 27.11.23

Начал делать terraform-инфраструктуру в yandex cloud. У меня уже был курс с [дипломным проектом](https://github.com/Kraktorist/build-stack), где я получил неплохой опыт работы с yandex.cloud, а также имел возможность потестировать разные подходы, отличавшиеся от тех, которые применял в работе.

Инфраструктуру опиcывал в виде единого yaml файла [config.yaml](./envs/dev/config.yaml), подающегося на вход terraform виде переменной. На выходе получал файл inventory.yaml, содержащий ansible inventory. Я уже знал, что такой подход хорошо работает, поскольку добавлять и удалять ресурсы можно простым редактированием yaml.

Немного недопонял, какие именно ресурсы разрешено использовать. Например, хотел попробовать использовать managed postgresql, но он оказался недоступен. В итоге остановился на реализации следующего минимума ресурсов:
- network
- subnet
- instance group
- instance
- container registry

В конечном проекте yandex container registry не использовал, загрузив образ на hub.docker.com

## 28.11.23

Реализовал установку `postgresql` с помощью `ansible` и импорт базы данных. Это позволило собрать полуработающую схему, где использовалась внешняя БД, а всё остальное работало в docker-compose.

Понял, что docker-compose не управляет unhealthy контейнерами, добавил сторожа в виде вспомогательного контейнера, рестартующего нездоровые контейнеры.

Реализовал установку nginx.

## 29.11.23

Работал над ошибками, возникающими в тестах. Делал [скриншоты](./status/) страницы отчетов, чтобы отслеживать свой прогресс.

Двумя наиболее времязатратными проблемами оказались следующие:

- **/api/session** запрос работал слишком долго. Посмотрел вывод этого http запроса, понял, что здесь вероятно используется медленный sql-запрос. Сам запрос попался мне в логе ошибок postgresql с текстом, что клиент не дождался ответа. Изначально запрос выполнялся более 30 секунд. Чтобы его ускорить, я просмотрел план запроса и пошел сразу по трем направлениям.
  1. Поместил БД на SSD диск.
  2. Посмотрел настройки сервера, понял, что используются дефолтные буферы, и увеличил значения `work_mem` и `shared_buffers`.
  3. Посмотрел индексы в БД и добавил дефолтные по id и по полям, использующимся для order by.

- **/long_dummy** кэширование. Вообще вопросов кэширования до этого не касался и предполагал, что здесь придется использовать какую-нибудь сложную схему с применением стороннего софта. В конце концов разобрался с настройками nginx.

## 30.11.23 

1. Закончил настройку кэширования.
2. Сделал https на самоподписном сертификате. Думал привязать домен и выпустить сертификат от let's encrypt, но из-за публичного динамического IP, меняющегося при каждом развертывании окружения, было бы тратой времени ждать обновления DNS записей.
3. Поработал над автоматизацией. Делать полноценный пайплайн не стал, а просто реализовал ./install.sh скрипт, которому можно передать имя окружения (то есть папки из envs/) и действие `apply` или `destroy`. За одну команду выполняется полная установка или удаление соответствующего окружения. Такой автоматизации достаточно, чтобы минут за 10-15 поднять пару независимых окружений и работать над одним из них, пока на втором идет автотест.
4. Начал работать над мониторингом. Посчитал, что `prometheus` и `grafana` будет достаточно для решения задачи, 

